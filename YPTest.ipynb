{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca733d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.api:Predicate set:\n",
      "INFO:dedupe.api:(SimplePredicate: (twoGramFingerprint, name), TfidfTextCanopyPredicate: (0.6, city), SimplePredicate: (sortedAcronym, phone))\n",
      "INFO:dedupe.api:(SimplePredicate: (commonThreeTokens, name), TfidfTextCanopyPredicate: (0.4, web), TfidfTextCanopyPredicate: (0.2, name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from csv_example_learned_settings\n",
      "reading labeled examples from  csv_example_training.json\n",
      "clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.canopy_index:Removing stop word com\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicate sets 2921\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import dedupe\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "\n",
    "input_file = 'readyDedupYp.csv'\n",
    "output_file = 'csv_example_output.csv'\n",
    "settings_file = 'csv_example_learned_settings'\n",
    "training_file = 'csv_example_training.json'\n",
    "\n",
    "\n",
    "def preProcess(column):\n",
    "    \"\"\"\n",
    "    Do a little bit of data cleaning with the help of Unidecode and Regex.\n",
    "    Things like casing, extra spaces, quotes and new lines can be ignored.\n",
    "    \"\"\"\n",
    "    try : # python 2/3 string differences\n",
    "        column = column.decode('utf8')\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    column = unidecode(column)\n",
    "    column = re.sub('  +', ' ', column)\n",
    "    column = re.sub('\\n', ' ', column)\n",
    "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
    "    # If data is missing, indicate that by setting the value to `None`\n",
    "    if not column:\n",
    "        column = None\n",
    "    return column\n",
    "\n",
    "def readData(filename):\n",
    "    \"\"\"\n",
    "    Read in our data from a CSV file and create a dictionary of records,\n",
    "    where the key is a unique record ID and each value is dict\n",
    "    \"\"\"\n",
    "\n",
    "    data_d = {}\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            clean_row = [(k, preProcess(v)) for (k, v) in row.items()]\n",
    "            row_id = int(row['Id'])\n",
    "            data_d[row_id] = dict(clean_row)\n",
    "\n",
    "    return data_d\n",
    "\n",
    "print('importing data ...')\n",
    "data_d = readData(input_file)\n",
    "\n",
    "# If a settings file already exists, we'll just load that and skip training\n",
    "if os.path.exists(settings_file):\n",
    "    print('reading from', settings_file)\n",
    "    with open(settings_file, 'rb') as f:\n",
    "        deduper = dedupe.StaticDedupe(f)\n",
    "else:\n",
    "    # ## Training\n",
    "    # Define the fields dedupe will pay attention to\n",
    "    fields = [\n",
    "        {'field': 'name', 'type': 'String'},\n",
    "        {'field': 'phone', 'type': 'String'},\n",
    "        {'field': 'streetAddress', 'type': 'String'},\n",
    "        {'field': 'city', 'type': 'String'},\n",
    "         {'field': 'state', 'type': 'String'},\n",
    "        {'field': 'web', 'type': 'String', 'has missing': True},\n",
    "    ]\n",
    "\n",
    "    # Create a new deduper object and pass our data model to it.\n",
    "    deduper = dedupe.Dedupe(fields)\n",
    "\n",
    "    ######  'Dedupe' object has no attribute 'sample' ###### \n",
    "\n",
    "if os.path.exists(training_file):\n",
    "    print('reading labeled examples from ', training_file)\n",
    "    #'StaticDedupe' object has no attribute 'prepare_training'\n",
    "    #with open(training_file, 'rb') as f:\n",
    "        #deduper.prepare_training(data_d, f) \n",
    "else:\n",
    "    deduper.prepare_training(data_d)\n",
    "    \n",
    "    \n",
    "    print('starting active labeling...')\n",
    "\n",
    "    dedupe.console_label(deduper) #https://github.com/dedupeio/dedupe-examples/issues/108\n",
    "\n",
    "    # Using the examples we just labeled, train the deduper and learn\n",
    "    # blocking predicates\n",
    "    deduper.train()\n",
    "\n",
    "    # When finished, save our training to disk\n",
    "    with open(training_file, 'w') as tf:\n",
    "        deduper.write_training(tf) #also seems to have had a name change\n",
    "\n",
    "    # Save our weights and predicates to disk.  If the settings file\n",
    "    # exists, we will skip all the training and learning next time we run\n",
    "    # this file.\n",
    "    with open(settings_file, 'wb') as sf:\n",
    "        deduper.write_settings(sf) #name change here too\n",
    "\n",
    "        \n",
    "#######'Dedupe' object has no attribute 'threshold'     \n",
    "print('clustering...')\n",
    "###clustered_dupes = deduper.match(data_d, threshold)\n",
    "clustered_dupes = deduper.partition(data_d, 0.5) \n",
    "\n",
    "print('# duplicate sets', len(clustered_dupes))\n",
    "\n",
    "# ## Writing Results\n",
    "\n",
    "# Write our original data back out to a CSV with a new column called\n",
    "# 'Cluster ID' which indicates which records refer to each other.\n",
    "\n",
    "cluster_membership = {}\n",
    "cluster_id = 0\n",
    "for (cluster_id, cluster) in enumerate(clustered_dupes):\n",
    "    id_set, scores = cluster\n",
    "    cluster_d = [data_d[c] for c in id_set]\n",
    "    canonical_rep = dedupe.canonicalize(cluster_d)\n",
    "    for record_id, score in zip(id_set, scores):\n",
    "        cluster_membership[record_id] = {\n",
    "            \"cluster id\" : cluster_id,\n",
    "            \"canonical representation\" : canonical_rep,\n",
    "            \"confidence\": score\n",
    "        }\n",
    "\n",
    "singleton_id = cluster_id + 1\n",
    "\n",
    "with open(output_file, 'w', newline = '') as f_output, open(input_file) as f_input:\n",
    "    writer = csv.writer(f_output)\n",
    "    reader = csv.reader(f_input)\n",
    "\n",
    "    heading_row = next(reader)\n",
    "    heading_row.insert(0, 'confidence_score')\n",
    "    heading_row.insert(0, 'Cluster ID')\n",
    "    canonical_keys = canonical_rep.keys()\n",
    "    for key in canonical_keys:\n",
    "        heading_row.append('canonical_' + key)\n",
    "\n",
    "    writer.writerow(heading_row)\n",
    "\n",
    "    for row in reader:\n",
    "        row_id = int(row[0])\n",
    "        if row_id in cluster_membership:\n",
    "            cluster_id = cluster_membership[row_id][\"cluster id\"]\n",
    "            canonical_rep = cluster_membership[row_id][\"canonical representation\"]\n",
    "            row.insert(0, cluster_membership[row_id]['confidence'])\n",
    "            row.insert(0, cluster_id)\n",
    "            for key in canonical_keys:\n",
    "                row.append(canonical_rep[key].encode('utf8'))\n",
    "        else:\n",
    "            row.insert(0, None)\n",
    "            row.insert(0, singleton_id)\n",
    "            singleton_id += 1\n",
    "            for key in canonical_keys:\n",
    "                row.append(None)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630f984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
